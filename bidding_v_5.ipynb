{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this version should be an upggrade of the previous one where I find a better way to give rewards. Instead of an ordinary TD(0) update as I used in the previous version I should now use a n-step method where I dont give rewards before every bid is given for an hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from code_map import final_markets, new_meters, utils, weather, timeframes, rl_utils, met_api, nve_api\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/utils.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.sort_values(by = \"Time\", inplace = True)\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/utils.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.sort_values(by = \"Time\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "tf = timeframes.one_week\n",
    "L, M, H = utils.get_all_sets(timeframe= tf, areas = [\"NO5\"])\n",
    "F, freq_data, _ = utils.get_frequency_sets(tf= tf, M =M, H= H)\n",
    "L_u, L_d, Fu_h_l, Fd_h_l, R_h_l, P_h_m, Vp_h_m, Vm_m, R_m = utils.get_parameters(L = L, M = M, H = H)\n",
    "Ir_hlm, Ia_hlm, Va_hm = utils.get_income_dictionaries(H=H, L = L, M = M, freq_data= freq_data, Fu_h_l= Fu_h_l, Fd_h_l= Fd_h_l, P_h_m= P_h_m, Vp_h_m= Vp_h_m, F = F, markets_dict = {market.name : market for market in M}, timeframe = tf, areas = [\"NO5\"])\n",
    "compatible_dict = utils.get_compatibility_dict(L = L ,M = M, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_market_names = [\"FCR\", \"aFRR\"]\n",
    "markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "exp_price_dict, exp_vol_dict = rl_utils.get_expected_prices_and_volumes_dict(bid_timeframe= H, markets= markets)\n",
    "norm_exp_price_dict = rl_utils.normalize_dict_vals(exp_price_dict, norm_method= \"min_max\")\n",
    "norm_exp_vol_dict = rl_utils.normalize_dict_vals(exp_vol_dict, norm_method= \"min_max\")\n",
    "weather_data = weather.get_weather_data(tf= tf, areas = [\"NO5\"])\n",
    "norm_w_df = rl_utils.normalize_weather_data(weather_data= weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@type': 'SensorSystem', 'id': 'SN47230', 'name': 'ÅKRA UNGDOMSSKOLE', 'shortName': 'Åkra ', 'country': 'Norge', 'countryCode': 'NO', 'geometry': {'@type': 'Point', 'coordinates': [5.1963, 59.2555], 'nearest': False}, 'masl': 18, 'validFrom': '2013-10-29T00:00:00.000Z', 'county': 'ROGALAND', 'countyId': 11, 'municipality': 'KARMØY', 'municipalityId': 1149, 'stationHolders': ['KARMØY KOMMUNE'], 'externalIds': ['506131077'], 'wigosId': '0-578-0-47230'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/met_api.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  area_df['coord_variance'] = area_df['coordinates'].apply(lambda x: np.var(x))\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/met_api.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  area_df['coord_variance'] = area_df['coordinates'].apply(lambda x: np.var(x))\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/met_api.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  area_df['coord_variance'] = area_df['coordinates'].apply(lambda x: np.var(x))\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/met_api.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  area_df['coord_variance'] = area_df['coordinates'].apply(lambda x: np.var(x))\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/met_api.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  area_df['coord_variance'] = area_df['coordinates'].apply(lambda x: np.var(x))\n"
     ]
    }
   ],
   "source": [
    "sources, sa_dict = met_api.get_station_ids(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ['air_temperature', 'sum(precipitation_amount P1D)', 'wind_speed', 'cloud_area_fraction']\n",
    "_, df2 = met_api.get_weather_data(start_month = tf.start_month, end_month = tf.end_month, start_day = tf.start_day, end_day = tf.end_day, start_year = tf.year, end_year = tf.year, wanted_sources= sources, sa_dict = sa_dict, wanted_elements= elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict = {}\n",
    "for val in df2[\"elementId\"].unique():\n",
    "    weather_dict[val] = met_api.get_wanted_weather_values(df2, elementId= val, area = \"NO5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_path = \"../master-data/spot_data/spot_june_23.csv\"\n",
    "norm_da_df = final_markets.preprocess_spot_data(pd.read_csv(spot_path), year = tf.year, start_month = tf.start_month, end_month = tf.end_month, start_day = tf.start_day, end_day = tf.end_day, start_hour = tf.start_hour, end_hour = tf.end_hour, area = \"NO5\", normalize= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FCR_D_D_1_NO5', 'FCR_D_D_2_NO5', 'FCR_N_D_1_NO5', 'FCR_N_D_2_NO5', 'aFRR up_NO5', 'aFRR down_NO5']\n"
     ]
    }
   ],
   "source": [
    "markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "print([m.name for m in markets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['air_temperature', 'sum(precipitation_amount P1D)', 'wind_speed', 'cloud_area_fraction'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_df = met_api.get_wanted_weather_values(df2, elementId= \"air_temperature\", area = \"NO5\")\n",
    "precipitation_df = met_api.get_wanted_weather_values(df2, elementId= \"sum(precipitation_amount P1D)\", area = \"NO5\")\n",
    "wind_speed_df = met_api.get_wanted_weather_values(df2, elementId= \"wind_speed\", area = \"NO5\")\n",
    "cloud_area_df = met_api.get_wanted_weather_values(df2, elementId= \"cloud_area_fraction\", area = \"NO5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(bid_hour : pd.Timestamp, available_assets : [new_meters.PowerMeter], market : final_markets.ReserveMarket, norm_exp_price_dict : dict, norm_exp_vol_dict : dict, norm_w_df : pd.DataFrame, norm_da_df : pd.DataFrame, L : [new_meters.PowerMeter], markets : [final_markets.ReserveMarket]):\n",
    "    \"\"\" Function to get the features for the given hour and market. It is important to use features that will help the model learn which actions to take \n",
    "        and update the weights correctly for the given state.\n",
    "        The features that possibly can be used here are the following:\n",
    "        - day of week\n",
    "        - hour of day\n",
    "        - number of possible assets\n",
    "        - Day Ahead (DA) price\n",
    "        - Weather forecast\n",
    "        - Market historical prices\n",
    "        - Market historical volumes\n",
    "        - frequency data (historical)\n",
    "        \n",
    "    Args:\n",
    "        available_assets (new_meters.PowerMeter]): _description_\n",
    "        hour (pd.Timestamp): _description_\n",
    "        market (final_markets.ReserveMarket): _description_\n",
    "        norm_exp_price_dict (dict) : dictionary of the normalized expected prices for each direction and area in the bid_timeframe \n",
    "        norm_exp_vol_dict (dict) : of the normalized expected volumes for each direction and area in the bid_timeframe \n",
    "        norm_w_df (pd.DataFrame) : normalized weather data \n",
    "        norm_da_df (pd.DataFrame) : normalized day ahead prices \n",
    "        L ([new_meters.PowerMeter]) : list of all possible assets\n",
    "\n",
    "    Returns:\n",
    "        np.array: np.array of the normalized features which depends on which market, hour and available assets are given\n",
    "    \"\"\"\n",
    "    day_of_week = bid_hour.weekday()\n",
    "    hour_of_day = bid_hour.hour\n",
    "    expected_price = norm_exp_price_dict[(market.direction, market.area, bid_hour)]\n",
    "    expected_volume = norm_exp_vol_dict[(market.direction, market.area, bid_hour)]\n",
    "    precipitation = norm_w_df[\"precipitation\"].loc[norm_w_df[\"Time (Local)\"] == bid_hour]\n",
    "    temperature = norm_w_df[\"air_temp\"].loc[norm_w_df[\"Time (Local)\"] == bid_hour]\n",
    "    da_price = norm_da_df[\"settlement\"].loc[norm_da_df[\"Time(Local)\"] == bid_hour]\n",
    "    market_nr = (markets.index(market)+1)/6\n",
    "    \n",
    "    \n",
    "    return np.array([day_of_week/7, hour_of_day/24, expected_price, expected_volume, len(available_assets)/len(L), precipitation.values[0], temperature.values[0], da_price.values[0], market_nr])\n",
    "\n",
    "# info opp til 2 dager tilbake i tid kan være interessant, (en type moving average e.l.), skal jeg da ha det for det markedet som er relevant eller for alle? Skal det være for prisene i markedene, volum, begge? DA priser? Vær?\n",
    "# uforventede utfall - umms - planlagte utfall ligger tilgjengelig - historiske umms ligger på nordpool. Trenger å vite tilgjegelig kapasitet og produksjon for forskjelige teknologier i hvert prisområde og om endringer er planlagt eller uplanlagt. når man får vite det\n",
    "# bør adde wind speed og skydekke. Dette sier litt om produksjon fra vind og sol og kan derfor påvirke priser. \n",
    "# czc mellom budområdene. Regnes ut ved å se på DA prisen for to dager siden og differanse mellom to budområder. \n",
    "# vannstand - hvor data hentes fra NVE. Det er interessant, spesielt å se på om vannstand i noen av kraftverkene er tett opp mot 100% av tilgjengelig kapasitet da de må se seg nødt til å produsere mer for å unngå oversvømmelse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(n_features :int , n_actions : int, zeros : bool = True):\n",
    "    if zeros:\n",
    "        return np.array([np.zeros((n_features)) for _ in range(n_actions)])\n",
    "    else:\n",
    "        return np.array([np.random.normal(0, 0.1, n_features) for _ in range(n_actions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nstep_model(epsilon : float, alpha : float, gamma : float, num_episodes : int, L : [new_meters.PowerMeter], M : [final_markets.ReserveMarket], H : [pd.Timestamp], norm_exp_price_dict : dict, norm_exp_vol_dict : dict, norm_w_df : pd.DataFrame, norm_da_df : pd.DataFrame, n_actions : int, n_features : int):\n",
    "    \"\"\" Training function to learn how to bid in to the markets due to the bidding constraints and the asset constraints as well as optimizing the weights. \n",
    "    The function will learn how to bid in to the markets by updating the weights due to the features. \n",
    "    The change from v_4 is that this function will compare bids that are set to the same hour to get a better estimate of the reward.\n",
    "    \n",
    "    Args:\n",
    "        epsilon (float): float number between 0 and 1, says how much the agent should explore\n",
    "        alpha (float): float number between 0 and 1, also known as the learning rate\n",
    "        gamma (float): float number between 0 and 1, also known as the discount factor\n",
    "        num_episodes (int): number of episodes to be ran\n",
    "        L ([new_meters.PowerMeter]): list of PowerMeter objects\n",
    "        M ([final_markets.Reservemarket]): list of ReserveMarket objects\n",
    "        H ([pd.Timestamp]): list of timestamps\n",
    "        norm_exp_price_dict (dict): dictionary of the normalized expected prices for each direction and area in the bid_timeframe\n",
    "        norm_exp_vol_dict (dict): dictionary of the normalized expected volumes for each direction and area in the bid_timeframe\n",
    "        norm_w_df (pd.DataFrame) : normalized weather data in pd.dataframe format\n",
    "        norm_da_df (pd.DataFrame) : normalized day ahead prices in pd.dataframe format\n",
    "        n_actions (int): number of actions\n",
    "        n_features (int): number of features\n",
    "\n",
    "    Returns:\n",
    "        bids (dict): dictionary that holds control over the final bids for each market and each hour. The keys are tuples of the market name and the hour and the values are the the assets that were bid for the given market and hour. The values are tuples including the list of assets and the aggregated volume.\n",
    "        revenues (dict): dictionary that holds the revenue for each episode\n",
    "        available_assets (dict): dictionary that holds the available assets for each hour\n",
    "        episode_weights (dict): dictionary that holds the weights for each episode\n",
    "        action_feature_dict: dictionary that holds the features for each action for each episode\n",
    "        asset_bids (list): list that holds the bids for each episode. The indexes are the episode number and the values are dataframes that holds the bids for each market and each hour for each episode.\n",
    "    \"\"\"\n",
    "    revenues = {}\n",
    "    bid_timeframe = H[24:] # the hours where bids can be placed in\n",
    "    place_bid_hours = [hour for hour in H[:-48] if hour.hour == 7 or hour.hour == 17 or hour.hour == 18] # the hours where bids can be placed from\n",
    "    bids = {}\n",
    "    asset_bids = []\n",
    "    sup_market_names = [\"FCR\", \"aFRR\"]\n",
    "    markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "    #market_names = [market.name for market in markets]\n",
    "    # will only use FCR-N, FCR-D and aFRR. The FCR markets are both D-1 and D-2 and the aFRR market is D-1 but it is both up and down\n",
    "    \n",
    "    available_assets = {hour: L.copy() for hour in bid_timeframe} \n",
    "    #bids = {(market.name, hour): [] for hour in bid_timeframe for market in markets}\n",
    "    \"For each hour, an action should be to either bid in every feasible asset, to bid the minimum volume or to bid nothing\"\n",
    "    (possible_hours, market_name) = rl_utils.get_possible_dates(place_bid_hours[0]) # the market_name is not the full name of the market, but rather a substring of the full name. Since FCR-D and FCR-N has the same deadlines there will be two markets with the same substring\n",
    "    \n",
    "    possible_markets = [m for m in markets if market_name in m.name] # will either be one or two markets\n",
    "    #indexes = [market_names.index(m.name) for m in possible_markets] # the indexes for each market. This is used to slice the Q-table so it is not necessary in this case\n",
    "    features = get_features(bid_hour = possible_hours[0], available_assets= available_assets[possible_hours[0]], market = possible_markets[0], norm_da_df=norm_da_df, norm_exp_price_dict= norm_exp_price_dict, norm_exp_vol_dict= norm_exp_vol_dict, norm_w_df= norm_w_df, L = L, markets= markets) # update the features\n",
    "\n",
    "    \n",
    "    action_0 = random.randint(0, n_actions-1)\n",
    "    action_feature_dict = {}\n",
    "    weights = initialize_weights(n_actions = n_actions, n_features = n_features, zeros = False)\n",
    "\n",
    "    # extract hours from H where hour == 7, 17, 18\n",
    "    epsilon_decay = epsilon/num_episodes\n",
    "    alpha_decay = alpha/num_episodes\n",
    "    episode_weights = {}\n",
    "    for episode_n in range(num_episodes):\n",
    "        if episode_n > episode_n/10:\n",
    "            epsilon -= epsilon_decay\n",
    "            alpha -= alpha_decay\n",
    "        revenue = 0\n",
    "        episode_bid_df = pd.DataFrame(columns= [\"Market\", \"Hour\", \"Asset Count\", \"Total Flex Volume\"])\n",
    "        episode_bid_dict = {}\n",
    "        reward_bid_hour_dict = {}\n",
    "       \n",
    "        #print(f\" weights at the start of episode nr {episode_n}: {weights}\")\n",
    "\n",
    "        available_assets = {hour: L.copy() for hour in bid_timeframe}\n",
    "        for place_hour in place_bid_hours: # the hours when the bids are placed from\n",
    "            (possible_hours, market_name) = rl_utils.get_possible_dates(place_hour) # returns the possible hours for the market to place bids in\n",
    "            if len(possible_hours) != 24:\n",
    "                print(f\"No bids for {place_hour}\")\n",
    "                print(f\"possible_hours: {len(possible_hours)}\")\n",
    "                break\n",
    "            #print(f\"possible_hours when bidding: {possible_hours}\")\n",
    "            possible_markets = [m for m in markets if market_name in m.name] # because i am now using only no5 markets, this list should be of length 1 or 2.\n",
    "            \n",
    "            for current_market in possible_markets: # the markets that are possible to bid in\n",
    "                #print(f\"current_market : {current_market.name}\")\n",
    "                for bid_hour in possible_hours:\n",
    "                    chosen_portfolio, reward, flex_vol = rl_utils.make_bid(current_market, bid_hour, action_0, available_assets[bid_hour], compatible_dict) # get portfolio and reward for a bid - will have to figure out a better way to define reward\n",
    "                    if bid_hour not in reward_bid_hour_dict.keys():\n",
    "                        reward_bid_hour_dict[bid_hour] = [reward]\n",
    "                    else:\n",
    "                        reward_bid_hour_dict[bid_hour].append(reward)\n",
    "\n",
    "                    available_assets[bid_hour] = [asset for asset in available_assets[bid_hour] if asset not in chosen_portfolio] # remove the assets that were bid from the available assets\n",
    "\n",
    "                    if len(chosen_portfolio) > 0:\n",
    "                        episode_bid_df.loc[len(episode_bid_df)] = [current_market.name, bid_hour, len(chosen_portfolio), flex_vol] # add the bid to the episode_bid_df\n",
    "\n",
    "                    episode_bid_dict[(current_market.name, bid_hour)] = (chosen_portfolio, flex_vol) # add the bid to the bids dictionary\n",
    "                    \n",
    "                    new_features = get_features(bid_hour = bid_hour, available_assets= available_assets[bid_hour], market = current_market, norm_da_df=norm_da_df, norm_exp_price_dict= norm_exp_price_dict, norm_exp_vol_dict= norm_exp_vol_dict, norm_w_df= norm_w_df, L = L, markets = markets) # update the features\n",
    "                    #print(f\"weights : {weights}\")\n",
    "                    possible_actions = [np.dot(weights[action], new_features) for action in range(n_actions)] \n",
    "                    \n",
    "                    new_action = rl_utils.greedy_action(possible_actions, epsilon)\n",
    "                    action_feature_dict[(episode_n, current_market.name, bid_hour)] = (action_0, new_action, features, new_features)\n",
    "                    features, action_0 = new_features, new_action\n",
    "                    revenue += reward\n",
    "            #print([m.name for m in possible_markets])\n",
    "            # Instead of updating the weights after each hour, the weights are updated after each market. This is to get a better estimate of the reward since the rewards are given after each of the markets are considererd for an hour.\n",
    "            if \"FCR_N_D_1_NO5\" in [m.name for m in possible_markets]: # The FCR D-1 markets has the latest deadline, so after these markets has been considered, all markets has been considered for the given hour.\n",
    "                #print(f\"Possible hours when updating the weights : {possible_hours}\")\n",
    "                for bid_hour in possible_hours: \n",
    "                    total_reward = sum(reward_bid_hour_dict[bid_hour])\n",
    "                    #print(f\"total_reward: {total_reward}\")\n",
    "                    for market in markets:\n",
    "                        if (episode_n, market.name, bid_hour) in action_feature_dict.keys(): # should maybe rearrange the structure of the code so that this if statement is not necessary\n",
    "                            action_0, new_action, features, new_features = action_feature_dict[(episode_n, market.name, bid_hour)]\n",
    "                            #delta = total_reward + np.dot(weights[new_action], new_features) - np.dot(weights[action_0], features)\n",
    "                            #weights = weights + alpha * delta * np.array(features + [action_0]) - denne har jeg ikke brukt \n",
    "                            #weights[action_0] = weights[action_0] + alpha * delta * features[action_0] # * features???\n",
    "                            q_values_next_state = np.array([np.dot(weights[a], new_features) for a in range(n_actions)])\n",
    "                            #print(f\"q_values_next_state: {q_values_next_state}\")\n",
    "                            \"\"\" print(type(weights), weights.shape)\n",
    "                            print(type(weights[action_0]), weights[action_0].shape)\n",
    "                            print(type(features), features.shape)\"\"\"\n",
    "                            #print(total_reward)\n",
    "                            #print(f\" updated weights : {weights[action_0] + alpha * (total_reward/1000 + gamma * np.max(q_values_next_state) - np.dot(weights[action_0], features)) * features}\")\n",
    "                            weights[action_0] = weights[action_0] + alpha * (total_reward/255 + gamma * np.max(q_values_next_state) - np.dot(weights[action_0], features)) * features\n",
    "                            #print(f\"weights after updating: {weights}\")\n",
    "\n",
    "        episode_weights[episode_n] = weights.copy()        \n",
    "        bids[episode_n] = episode_bid_df.sort_values(by = [\"Hour\"])\n",
    "        revenues[episode_n] = revenue\n",
    "        asset_bids.append(episode_bid_dict)\n",
    "    return bids, revenues, available_assets, episode_weights, action_feature_dict, asset_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids, revenues, available_assets, weights, action_list, asset_bids = train_nstep_model(epsilon = 0.3, alpha = 0.3, gamma = 0.9, num_episodes = 100, L = L, M = M, H = H, norm_exp_price_dict = norm_exp_price_dict, norm_exp_vol_dict = norm_exp_vol_dict, norm_w_df = norm_w_df, norm_da_df = norm_da_df, n_features= 9, n_actions= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {}\n",
    "for e in range(2):\n",
    "    action_0s = []\n",
    "    actions = []\n",
    "    feature_list = []\n",
    "    new_feature_list = []    \n",
    "    for market in markets:\n",
    "        for hour in H:\n",
    "            if (e, market.name, hour) in action_list.keys():\n",
    "                action_0, new_action, features, new_features = action_list[(e, market.name, hour)]\n",
    "                action_0s.append(action_0)\n",
    "                actions.append(new_action)\n",
    "                feature_list.append(features)\n",
    "                new_feature_list.append(new_features)\n",
    "\n",
    "    action_dict[e] = (action_0s, actions, feature_list, new_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict[0][0] == action_dict[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0] == weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def make_plots_for_sol(dict_of_dfs : dict, sol_name : str = \"Optimization\", rl_df : pd.DataFrame = None, y_axis : str = \"Asset Count\"):\n",
    "    \"\"\" function to make plot of the results recieved from the wanted model. This function can either plot how many assets that were bid in each market for each hour or the total flex volume that was bid in each market for each hour.\n",
    "\n",
    "    Args:\n",
    "        dict_of_dfs (dict): for the optimization model, the results are stored in a dict. The keys are the hours and the values are dataframes that holds the results for each hour.\n",
    "        sol_name (str, optional): Either \"Optimization\" or \"RL. Defaults to \"Optimization\".\n",
    "        rl_df (pd.DataFrame, optional): The results for the RL df are stored in a dataframe and this should be given here if the results from the RL model is wanted. The RL model returns a list of dataframes, and that list with the wanted index (episode) should be given. Defaults to None.\n",
    "        y_axis (str, optional): Choose which y-axis value that is wanted. Can be either \"Asset Count\" or \"Total Flex Volume\". Defaults to \"Asset Count\".\n",
    "    \"\"\"\n",
    "    if sol_name == \"Optimization\":\n",
    "        combined_df = pd.concat(dict_of_dfs, ignore_index=True)\n",
    "        combined_df = combined_df.loc[combined_df[\"Hour\"]>= pd.Timestamp(2023, 6, 20, 0, 0, 0, tz = \"Europe/Oslo\")]\n",
    "    else:\n",
    "        combined_df = rl_df.copy()\n",
    "    # Create a figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    # Iterate over each market and add a scatter trace for Asset Count and Total Flex Volume\n",
    "    for market in combined_df['Market'].unique():\n",
    "        market_data = combined_df[combined_df['Market'] == market]\n",
    "        if y_axis == \"Asset Count\":\n",
    "            # Scatter for Asset Count\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=market_data['Hour'], y=market_data['Asset Count'], \n",
    "                        mode='markers', name=f\"Asset Count - {market}\"),\n",
    "                secondary_y=False,\n",
    "            )\n",
    "        elif y_axis == \"Total Flex Volume\":\n",
    "            # Scatter for Total Flex Volume\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=market_data['Hour'], y=market_data['Total Flex Volume'], \n",
    "                        mode='markers', name=f\"Total Flex Volume - {market}\"),\n",
    "                secondary_y=True,\n",
    "            )\n",
    "\n",
    "    # Add figure title and layout\n",
    "    fig.update_layout(title_text=f\"{y_axis} by Market and Hour from the {sol_name} model\")\n",
    "\n",
    "    # Set x-axis title\n",
    "    fig.update_xaxes(title_text=\"Hours\")\n",
    "\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"Asset Count\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Total Flex Volume\", secondary_y=True)\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots_for_sol(None, sol_name= \"RL\", rl_df= bids[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x= [i for i in range(len(revenues.keys()))], y= [i for i in revenues.values()], mode= \"markers\"))\n",
    "# add title and axis labels\n",
    "fig.update_layout(title_text=\"Revenue per episode for RL model\", xaxis_title=\"Episode\", yaxis_title=\"Revenue\")\n",
    "# add a regression line for the revenue values for each episode.\n",
    "fig.add_trace(go.Scatter(x= [i for i in range(len(revenues.keys()))], y= [i for i in revenues.values()], mode= \"lines\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for w in range(3):\n",
    "    fig.add_trace(go.Scatter(x= [i for i in range(len(weights.keys()))], y= [np.sum(i[w]) for i in list(weights.values())], mode= \"markers\", name= f\"weight {w}\"))\n",
    "# add title and axis labels\n",
    "fig.update_layout(title_text=\"Weights per episode for RL model\", xaxis_title=\"Episode\", yaxis_title=\"sum of the weights\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(3):\n",
    "    fig = go.Figure()\n",
    "    for f in range(9):\n",
    "        fig.add_trace(go.Scatter(x= [i for i in range(len(weights.keys()))], y= [np.sum(i[w, f]) for i in list(weights.values())], mode= \"markers\", name= f\"feature {f} for weight {w}\"))\n",
    "    fig.update_layout(title_text=f\"Weights per episode for RL model for weight {w}\", xaxis_title=\"Episode\", yaxis_title=\"sum of the weights\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compatible_list = utils.get_compatibility_dict(L = L, M = M, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, x, y, w, d = utils.run_optimization_model(L = L, M = M, F = F, H = H, Fu_h_l = Fu_h_l, Fd_h_l = Fd_h_l, R_h_l = R_h_l, Vp_h_m = Vp_h_m, Vm_m = Vm_m, R_m = R_m, Ir_hlm = Ir_hlm, Ia_hlm = Ia_hlm, Va_hm = Va_hm, compatible_list= compatible_list, log_filename= \"week_mod_no5.log\", model_name= \"week_mod_no5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The functions below are to check the revenue for each hour for the optimization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_count_df(x : dict, y: dict, w : dict,  H : [pd.Timestamp], L : [new_meters.PowerMeter], M : [final_markets.ReserveMarket]):\n",
    "    \"\"\" function to get a dictionary of the results of the optimization problem.\n",
    "        The solution is represented as a dataframe for each hour which tells how many assets and how much flex volume is connected to each market for each hour.\n",
    "\n",
    "    Args:\n",
    "        x (dict): dictionary of the binary variable which tells if an asset is connected to a market\n",
    "        L (list(PowerMeter)): list of powermeter objects with the data for each meter within the timeframe\n",
    "        M (list(ReserveMarket)): list of reservemarket objects with the data for each market within the timeframe\n",
    "        H (list(pd.TimeStamp)): list of hourly timestamps within the timeframe\n",
    "        dominant_directions (list(str)): list of the dominant direction for each hour\n",
    "\n",
    "    Returns:\n",
    "        dict: the solution of the optimization problem\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Market\", \"Hour\", \"Asset Count\",\"Total Flex Volume [MWh]\", \"Total capacity revenue [EUR]\", \"Total activation revenue [EUR]\"])\n",
    "    for h, hour in enumerate(H):\n",
    "        for m, market in enumerate(M):\n",
    "            if y[h, m].X > 0:\n",
    "                amount_of_assets = sum(x[h, l, m].X for l in range(len(L)))\n",
    "                capacity_income = sum(x[h, l, m].X * Ir_hlm[h, l, m] for l in range(len(L)))\n",
    "                activation_income = sum(x[h, l, m].X * Ia_hlm[h, l, m] * w[h,m].X for l in range(len(L)))\n",
    "                if market.direction == \"up\":\n",
    "                    total_flex_volume = sum(x[h, l, m].X * Fu_h_l[h,l] for l in range(len(L)))\n",
    "                elif market.direction == \"down\":\n",
    "                    total_flex_volume = sum(x[h, l, m].X * Fd_h_l[h,l] for l in range(len(L)))\n",
    "                else:\n",
    "                    total_flex_volume = 0\n",
    "                    for l, load in enumerate(L):\n",
    "                        if load.direction == \"up\":\n",
    "                            total_flex_volume += x[h, l, m].X * Fu_h_l[h,l]\n",
    "                        elif load.direction == \"down\":\n",
    "                            total_flex_volume += x[h, l, m].X * Fd_h_l[h,l]\n",
    "                        else:\n",
    "                            total_flex_volume += min(x[h, l, m].X * Fu_h_l[h,l], x[h, l, m].X * Fd_h_l[h,l])\n",
    "                           \n",
    "                df.loc[len(df)] = [market.name, hour, amount_of_assets, total_flex_volume, capacity_income, activation_income]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd = get_market_count_df(x = x,y =y, w = w, H = H, L = L, M = M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcd[\"Market\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mcd[\"Total capacity revenue [EUR]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mcd[\"Total activation revenue [EUR]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_df_sum = sum(mcd[\"Total capacity revenue [EUR]\"]) + sum(mcd[\"Total activation revenue [EUR]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_mod_tot_rev = sum(x[h,l,m].X * (Ir_hlm[h,l,m] + Ia_hlm[h,l,m] * w[h,m].X) for h in range(len(H)) for l in range(len(L)) for m in range(len(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_mod_tot_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_income = mcd[\"Total capacity revenue [EUR]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(capacity_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-kode-mqTzi66U-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
