{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this version I will integrate a neural netwrok to my reinforcement learning model to enhance its ability to capture complex patterns and relationships in the data thar a linear model might miss. This approach is commonly known as a Deep-Q-Netork (DQN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from code_map import final_markets, new_meters, utils,  timeframes, rl_utils, met_api, nve_api\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = timeframes.one_week\n",
    "areas = [\"NO5\"]\n",
    "norm_method = \"min_max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/utils.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.sort_values(by = \"Time\", inplace = True)\n",
      "/Users/sandermeland/Documents/UIB/Master/master-kode/code_map/utils.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.sort_values(by = \"Time\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "L, M, H = utils.get_all_sets(timeframe= tf, areas = areas)\n",
    "F, freq_data, _ = utils.get_frequency_sets(tf= tf, M =M, H= H)\n",
    "L_u, L_d, Fu_h_l, Fd_h_l, R_h_l, P_h_m, Vp_h_m, Vm_m, R_m = utils.get_parameters(L = L, M = M, H = H)\n",
    "Ir_hlm, Ia_hlm, Va_hm = utils.get_income_dictionaries(H=H, L = L, M = M, freq_data= freq_data, Fu_h_l= Fu_h_l, Fd_h_l= Fd_h_l, P_h_m= P_h_m, Vp_h_m= Vp_h_m, F = F, markets_dict = {market.name : market for market in M}, timeframe = tf, areas = areas)\n",
    "compatible_dict = utils.get_compatibility_dict(L = L ,M = M, index = False)\n",
    "compatible_list = utils.get_compatibility_dict(L = L ,M = M, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_market_names = [\"FCR\", \"aFRR\"]\n",
    "markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "exp_price_dict, exp_vol_dict = rl_utils.get_expected_prices_and_volumes_dict(bid_timeframe= H, markets= markets)\n",
    "norm_exp_price_dict = rl_utils.normalize_dict_vals(exp_price_dict, norm_method= norm_method)\n",
    "norm_exp_vol_dict = rl_utils.normalize_dict_vals(exp_vol_dict, norm_method= norm_method)\n",
    "weather_dict = met_api.get_normalized_weather_dfs(reference_tf= timeframes.one_month, usage_tf = tf, areas = areas)\n",
    "\n",
    "spot_path = \"../master-data/spot_data/spot_june_23.csv\"\n",
    "norm_da_df = final_markets.preprocess_spot_data(pd.read_csv(spot_path), year = tf.year, start_month = tf.start_month, end_month = tf.end_month, start_day = tf.start_day, end_day = tf.end_day, start_hour = tf.start_hour, end_hour = tf.end_hour, area = \"NO5\", normalize= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp_df = weather_dict[(\"air_temperature\", areas[0])]\n",
    "wind_speed_df = weather_dict[(\"wind_speed\", areas[0])]\n",
    "precipitation_df = weather_dict[(\"sum(precipitation_amount P1D)\", areas[0])]\n",
    "cloud_cover_df = weather_dict[(\"cloud_area_fraction\", areas[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FCR_D_D_1_NO5', 'FCR_D_D_2_NO5', 'FCR_N_D_1_NO5', 'FCR_N_D_2_NO5', 'aFRR up_NO5', 'aFRR down_NO5']\n"
     ]
    }
   ],
   "source": [
    "markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "print([m.name for m in markets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(bid_hour : pd.Timestamp, available_assets : [new_meters.PowerMeter], market : final_markets.ReserveMarket, \n",
    "                 norm_exp_price_dict : dict, norm_exp_vol_dict : dict, precipitation_df : pd.DataFrame, air_temp_df : pd.DataFrame, \n",
    "                 cloud_cover_df : pd.DataFrame, wind_speed_df : pd.DataFrame, norm_da_df : pd.DataFrame, L : [new_meters.PowerMeter], \n",
    "                 markets : [final_markets.ReserveMarket]):\n",
    "    \"\"\" Function to get the features for the given hour and market. It is important to use features that will help the model learn which actions to take \n",
    "        and update the weights correctly for the given state.\n",
    "        The features that possibly can be used here are the following:\n",
    "        - day of week\n",
    "        - hour of day\n",
    "        - number of possible assets\n",
    "        - Day Ahead (DA) price\n",
    "        - Weather forecast including precipitation, temperature, wind speed and cloud cover\n",
    "        - Market historical prices\n",
    "        - Market historical volumes\n",
    "        - frequency data (historical)\n",
    "\n",
    "        Will add more features as I go along. Fyllingsgrad is ready to be added, but I only have weekly values which means that it will be the same for all hours in the week.\n",
    "        \n",
    "    Args:\n",
    "        available_assets (new_meters.PowerMeter]): _description_\n",
    "        hour (pd.Timestamp): _description_\n",
    "        market (final_markets.ReserveMarket): _description_\n",
    "        norm_exp_price_dict (dict) : dictionary of the normalized expected prices for each direction and area in the bid_timeframe \n",
    "        norm_exp_vol_dict (dict) : of the normalized expected volumes for each direction and area in the bid_timeframe \n",
    "        norm_w_df (pd.DataFrame) : normalized weather data \n",
    "        norm_da_df (pd.DataFrame) : normalized day ahead prices \n",
    "        L ([new_meters.PowerMeter]) : list of all possible assets\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: normalized features which depends on which market, hour and available assets are given\n",
    "    \"\"\"\n",
    "    day_of_week = bid_hour.weekday()\n",
    "    hour_of_day = bid_hour.hour\n",
    "    expected_price = norm_exp_price_dict[(market.direction, market.area, bid_hour)]\n",
    "    expected_volume = norm_exp_vol_dict[(market.direction, market.area, bid_hour)]\n",
    "    #precipitation = norm_w_df[\"precipitation\"].loc[norm_w_df[\"Time (Local)\"] == bid_hour]\n",
    "    #temperature = norm_w_df[\"air_temp\"].loc[norm_w_df[\"Time (Local)\"] == bid_hour]\n",
    "    precipitation = precipitation_df.loc[bid_hour.replace(hour= 0, minute= 0, second= 0, microsecond= 0)]\n",
    "    temperature = air_temp_df.loc[bid_hour]\n",
    "    wind_speed = wind_speed_df.loc[bid_hour]\n",
    "    cloud_cover = cloud_cover_df.loc[bid_hour.replace(hour= 0, minute= 0, second= 0, microsecond= 0)]\n",
    "    da_price = norm_da_df[\"settlement\"].loc[norm_da_df[\"Time(Local)\"] == bid_hour]\n",
    "    market_nr = (markets.index(market)+1)/6\n",
    "    \n",
    "    return torch.tensor([day_of_week/7, hour_of_day/24, expected_price, expected_volume, len(available_assets)/len(L), precipitation, temperature, wind_speed, cloud_cover, da_price.values[0], market_nr], dtype=torch.float32)\n",
    "\n",
    "# info opp til 2 dager tilbake i tid kan være interessant, (en type moving average e.l.), skal jeg da ha det for det markedet som er relevant eller for alle? Skal det være for prisene i markedene, volum, begge? DA priser? Vær?\n",
    "# uforventede utfall - umms - planlagte utfall ligger tilgjengelig - historiske umms ligger på nordpool. Trenger å vite tilgjegelig kapasitet og produksjon for forskjelige teknologier i hvert prisområde og om endringer er planlagt eller uplanlagt. når man får vite det\n",
    "# bør adde wind speed og skydekke. Dette sier litt om produksjon fra vind og sol og kan derfor påvirke priser. \n",
    "# czc mellom budområdene. Regnes ut ved å se på DA prisen for to dager siden og differanse mellom to budområder. \n",
    "# vannstand - hvor data hentes fra NVE. Det er interessant, spesielt å se på om vannstand i noen av kraftverkene er tett opp mot 100% av tilgjengelig kapasitet da de må se seg nødt til å produsere mer for å unngå oversvømmelse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.output = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearQNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(linearQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Func.relu(self.fc1(x))\n",
    "        x = Func.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network, optimizer, actions, new_actions, features, new_features, gamma, batch_size, rewards):\n",
    "    \"\"\"\n",
    "    Update the weights of the neural network based on the provided batch of experiences and return the updated weights.\n",
    "\n",
    "    Args:\n",
    "        network (torch.nn.Module): The neural network whose weights will be updated.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for updating the weights.\n",
    "        actions (list of int): Actions taken at each timestep.\n",
    "        new_actions (list of int): Actions taken at the next timestep.\n",
    "        features (torch.tensor): Features for each timestep.\n",
    "        new_features (torch.tensor): Features for the next timestep.\n",
    "        gamma (float): Discount factor for future rewards.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated weights of the neural network.\n",
    "    \"\"\"\n",
    "  \n",
    "    current_q_values = network(new_features).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Get the predicted Q-values for the next states\n",
    "    next_q_values = network(new_features).max(1)[0]\n",
    "\n",
    "    # Calculate the target Q-values including the immediate reward\n",
    "    target_q_values = rewards + gamma * next_q_values\n",
    "\n",
    "    # Compute loss\n",
    "    loss = F.mse_loss(current_q_values, target_q_values.detach())\n",
    "\n",
    "    # Zero the gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return the updated weights\n",
    "    return network.state_dict(), loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(n_features :int , n_actions : int, zeros : bool = False):\n",
    "    \"\"\" Function to initialize the weights to use in the RL model\n",
    "\n",
    "    Args:\n",
    "        n_features (int): number of features\n",
    "        n_actions (int): number of actions\n",
    "        zeros (bool, optional): If True, the weights will be initialized to zeros. Defaults to False which means that the weights will be initialized to random values between 0 and 0.1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The weights in a tensor of shape (n_actions, n_features)\n",
    "    \"\"\"\n",
    "    if zeros:\n",
    "        return torch.zeros((n_actions, n_features), dtype=torch.float32)\n",
    "    else:\n",
    "        # Initialize with random values from a normal distribution\n",
    "        return torch.randn((n_actions, n_features), dtype=torch.float32) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nstep_model(epsilon : float, alpha : float, gamma : float, num_episodes : int, L : [new_meters.PowerMeter], M : [final_markets.ReserveMarket], H : [pd.Timestamp], norm_exp_price_dict : dict, norm_exp_vol_dict : dict, weather_dict : dict, norm_da_df : pd.DataFrame, n_actions : int, n_features : int):\n",
    "    \"\"\" Training function to learn how to bid in to the markets due to the bidding constraints and the asset constraints as well as optimizing the weights. \n",
    "    The function will learn how to bid in to the markets by updating the weights due to the features. \n",
    "    The change from v_4 is that this function will compare bids that are set to the same hour to get a better estimate of the reward.\n",
    "    The change from v_5 is that this function will use a neural network instead of a Q-table to update the weights.\n",
    "    \n",
    "    Args:\n",
    "        epsilon (float): float number between 0 and 1, says how much the agent should explore\n",
    "        alpha (float): float number between 0 and 1, also known as the learning rate\n",
    "        gamma (float): float number between 0 and 1, also known as the discount factor\n",
    "        num_episodes (int): number of episodes to be ran\n",
    "        L ([new_meters.PowerMeter]): list of PowerMeter objects\n",
    "        M ([final_markets.Reservemarket]): list of ReserveMarket objects\n",
    "        H ([pd.Timestamp]): list of timestamps\n",
    "        norm_exp_price_dict (dict): dictionary of the normalized expected prices for each direction and area in the bid_timeframe\n",
    "        norm_exp_vol_dict (dict): dictionary of the normalized expected volumes for each direction and area in the bid_timeframe\n",
    "        weather_dict (dict): dictionary of the normalized weather data\n",
    "        norm_da_df (pd.DataFrame) : normalized day ahead prices in pd.dataframe format\n",
    "        n_actions (int): number of actions\n",
    "        n_features (int): number of features\n",
    "\n",
    "    Returns:\n",
    "        bids (dict): dictionary that holds control over the final bids for each market and each hour. The keys are tuples of the market name and the hour and the values are the the assets that were bid for the given market and hour. The values are tuples including the list of assets and the aggregated volume.\n",
    "        revenues (dict): dictionary that holds the revenue for each episode\n",
    "        available_assets (dict): dictionary that holds the available assets for each hour\n",
    "        episode_weights (dict): dictionary that holds the weights for each episode\n",
    "        action_feature_dict: dictionary that holds the features for each action for each episode\n",
    "        asset_bids (list): list that holds the bids for each episode. The indexes are the episode number and the values are dataframes that holds the bids for each market and each hour for each episode.\n",
    "    \"\"\"\n",
    "    revenues = {}\n",
    "    bid_timeframe = H[48:] # the hours where bids can be placed in\n",
    "    place_bid_hours = [hour for hour in H[24:-48] if hour.hour == 7 or hour.hour == 17 or hour.hour == 18] # the hours where bids can be placed from\n",
    "    bids = {}\n",
    "    asset_bids = []\n",
    "    sup_market_names = [\"FCR\", \"aFRR\"]\n",
    "    markets = [market for market in M if sup_market_names[0] in market.name  or sup_market_names[1] in market.name]\n",
    "    #market_names = [market.name for market in markets]\n",
    "    # will only use FCR-N, FCR-D and aFRR. The FCR markets are both D-1 and D-2 and the aFRR market is D-1 but it is both up and down\n",
    "    air_temp_df = weather_dict[(\"air_temperature\", areas[0])]\n",
    "    wind_speed_df = weather_dict[(\"wind_speed\", areas[0])]\n",
    "    precipitation_df = weather_dict[(\"sum(precipitation_amount P1D)\", areas[0])]\n",
    "    cloud_cover_df = weather_dict[(\"cloud_area_fraction\", areas[0])]\n",
    "\n",
    "    available_assets = {hour: L.copy() for hour in bid_timeframe} \n",
    "    #bids = {(market.name, hour): [] for hour in bid_timeframe for market in markets}\n",
    "    \"For each hour, an action should be to either bid in every feasible asset, to bid the minimum volume or to bid nothing\"\n",
    "    (possible_hours, market_name) = rl_utils.get_possible_dates(place_bid_hours[0]) # the market_name is not the full name of the market, but rather a substring of the full name. Since FCR-D and FCR-N has the same deadlines there will be two markets with the same substring\n",
    "    \n",
    "    possible_markets = [m for m in markets if market_name in m.name] # will either be one or two markets\n",
    "    #indexes = [market_names.index(m.name) for m in possible_markets] # the indexes for each market. This is used to slice the Q-table so it is not necessary in this case\n",
    "    features = get_features(bid_hour = possible_hours[0], available_assets= available_assets[possible_hours[0]], \n",
    "                            market = possible_markets[0],norm_da_df=norm_da_df, norm_exp_price_dict= norm_exp_price_dict, \n",
    "                            norm_exp_vol_dict= norm_exp_vol_dict, precipitation_df= precipitation_df, cloud_cover_df= cloud_cover_df, \n",
    "                            wind_speed_df= wind_speed_df, air_temp_df= air_temp_df, L = L, markets = markets)\n",
    "\n",
    "    \n",
    "    action_0 = random.randint(0, n_actions-1)\n",
    "    action_feature_dict = {}\n",
    "    weights = initialize_weights(n_actions = n_actions, n_features = n_features, zeros = False)\n",
    "    hidden_sizes = [64,64]\n",
    "    device = (\n",
    "            torch.device('cuda') if torch.cuda.is_available()\n",
    "            else torch.device('cpu'))\n",
    "    #network = QNetwork(input_size = n_features, output_size = n_actions, batch_size= 6*24, hidden_sizes = hidden_sizes).to(device = device)\n",
    "    network = QNetwork(input_size = n_features, output_size = n_actions, hidden_sizes = hidden_sizes).to(device = device)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "    # extract hours from H where hour == 7, 17, 18\n",
    "    epsilon_decay = epsilon/num_episodes\n",
    "    alpha_decay = alpha/num_episodes\n",
    "    episode_weights = {}\n",
    "    episode_losses = {}\n",
    "\n",
    "    for episode_n in range(num_episodes):\n",
    "        ep_loss = 0\n",
    "        if episode_n > episode_n/10:\n",
    "            epsilon -= epsilon_decay\n",
    "            alpha -= alpha_decay\n",
    "        revenue = 0\n",
    "        episode_bid_df = pd.DataFrame(columns= [\"Market\", \"Hour\", \"Asset Count\", \"Total Flex Volume\"])\n",
    "        episode_bid_dict = {}\n",
    "        reward_bid_hour_dict = {}\n",
    "        if episode_n == 0:\n",
    "            (D_2_hours, D_2_names) = rl_utils.get_possible_dates(H[17]) # returns the possible hours for the market to place bids in\n",
    "            D_2_markets = [m for m in markets if D_2_names in m.name] # because i am now using only no5 markets, this list should be of length 2.\n",
    "            print([m.name for m in D_2_markets])\n",
    "            for D_2_market in D_2_markets: # the markets that are possible to bid in\n",
    "                for D_2_hour in D_2_hours:\n",
    "                    chosen_portfolio, reward, flex_vol = rl_utils.make_bid(D_2_market, D_2_hour, action_0, available_assets[D_2_hour], compatible_dict) # get portfolio and reward for a bid - will have to figure out a better way to define reward\n",
    "                    if D_2_hour not in reward_bid_hour_dict.keys():\n",
    "                        reward_bid_hour_dict[D_2_hour] = [reward]\n",
    "                    else:\n",
    "                        reward_bid_hour_dict[D_2_hour].append(reward)\n",
    "\n",
    "                    available_assets[D_2_hour] = [asset for asset in available_assets[D_2_hour] if asset not in chosen_portfolio] # remove the assets that were bid from the available assets\n",
    "\n",
    "                    if len(chosen_portfolio) > 0:\n",
    "                        episode_bid_df.loc[len(episode_bid_df)] = [D_2_market.name, D_2_hour, len(chosen_portfolio), flex_vol] # add the bid to the episode_bid_df\n",
    "\n",
    "                    episode_bid_dict[(D_2_market.name, D_2_hour)] = (chosen_portfolio, flex_vol) # add the bid to the bids dictionary\n",
    "                    \n",
    "                    new_features = get_features(bid_hour = D_2_hour, available_assets= available_assets[D_2_hour], \n",
    "                                                market = D_2_market, norm_da_df=norm_da_df, norm_exp_price_dict= norm_exp_price_dict, \n",
    "                                                norm_exp_vol_dict= norm_exp_vol_dict, precipitation_df= precipitation_df, cloud_cover_df= cloud_cover_df, \n",
    "                                                wind_speed_df= wind_speed_df, air_temp_df= air_temp_df, L = L, markets = markets) # update the features\n",
    "                    #print(f\"weights : {weights}\")\n",
    "                    possible_actions = torch.tensor([torch.matmul(weights[action], features) for action in range(n_actions)], dtype=torch.float32)\n",
    "                    #print(f\"possible actions : {possible_actions}\")\n",
    "                    \n",
    "                    new_action = rl_utils.greedy_action(possible_actions, epsilon)\n",
    "                    action_feature_dict[(episode_n, D_2_market.name, D_2_hour)] = (action_0, new_action, features, new_features)\n",
    "                    features, action_0 = new_features, new_action\n",
    "                    revenue += reward\n",
    "       \n",
    "        #print(f\" weights at the start of episode nr {episode_n}: {weights}\")\n",
    "        #features, action_0, revenue, new_features, episode_bid_dict, available_assets, reward_bid_hour_dict, episode_bid_df, action_feature_dict = one_episode_actions(episode_n = episode_n, epsilon = epsilon, alpha = alpha, gamma = gamma, L = L, M = M, H = H, norm_exp_price_dict = norm_exp_price_dict, norm_exp_vol_dict = norm_exp_vol_dict, weather_dict = weather_dict, norm_da_df = norm_da_df, n_actions = n_actions, n_features = n_features, markets = markets, bid_timeframe = bid_timeframe, place_bid_hours = place_bid_hours, available_assets = available_assets, weights = weights, action_0 = action_0, revenue = revenue, episode_bid_dict = episode_bid_dict, reward_bid_hour_dict = reward_bid_hour_dict, episode_bid_df = episode_bid_df, action_feature_dict = action_feature_dict, precipitation_df = precipitation_df, cloud_cover_df = cloud_cover_df, wind_speed_df = wind_speed_df, air_temp_df = air_temp_df)\n",
    "        available_assets = {hour: L.copy() for hour in bid_timeframe}\n",
    "        for place_hour in place_bid_hours: # the hours when the bids are placed from\n",
    "            (possible_hours, market_name) = rl_utils.get_possible_dates(place_hour) # returns the possible hours for the market to place bids in\n",
    "           \n",
    "            possible_markets = [m for m in markets if market_name in m.name] # because i am now using only no5 markets, this list should be of length 2.\n",
    "            #print([m.name for m in possible_markets])\n",
    "            \n",
    "            for current_market in possible_markets: # the markets that are possible to bid in\n",
    "                for bid_hour in possible_hours:\n",
    "                    chosen_portfolio, reward, flex_vol = rl_utils.make_bid(current_market, bid_hour, action_0, available_assets[bid_hour], compatible_dict) # get portfolio and reward for a bid - will have to figure out a better way to define reward\n",
    "                    if bid_hour not in reward_bid_hour_dict.keys():\n",
    "                        reward_bid_hour_dict[bid_hour] = [reward]\n",
    "                    else:\n",
    "                        reward_bid_hour_dict[bid_hour].append(reward)\n",
    "\n",
    "                    available_assets[bid_hour] = [asset for asset in available_assets[bid_hour] if asset not in chosen_portfolio] # remove the assets that were bid from the available assets\n",
    "\n",
    "                    if len(chosen_portfolio) > 0:\n",
    "                        episode_bid_df.loc[len(episode_bid_df)] = [current_market.name, bid_hour, len(chosen_portfolio), flex_vol] # add the bid to the episode_bid_df\n",
    "\n",
    "                    episode_bid_dict[(current_market.name, bid_hour)] = (chosen_portfolio, flex_vol) # add the bid to the bids dictionary\n",
    "                    \n",
    "                    new_features = get_features(bid_hour = bid_hour, available_assets= available_assets[bid_hour], \n",
    "                                                market = current_market, norm_da_df=norm_da_df, norm_exp_price_dict= norm_exp_price_dict, \n",
    "                                                norm_exp_vol_dict= norm_exp_vol_dict, precipitation_df= precipitation_df, cloud_cover_df= cloud_cover_df, \n",
    "                                                wind_speed_df= wind_speed_df, air_temp_df= air_temp_df, L = L, markets = markets) # update the features\n",
    "                    #print(f\"weights : {weights}\")\n",
    "                    possible_actions = torch.tensor([torch.matmul(weights[action], features) for action in range(n_actions)], dtype=torch.float32)\n",
    "                    #print(f\"possible actions : {possible_actions}\")\n",
    "                    \n",
    "                    new_action = rl_utils.greedy_action(possible_actions, epsilon)\n",
    "                    action_feature_dict[(episode_n, current_market.name, bid_hour)] = (action_0, new_action, features, new_features)\n",
    "                    features, action_0 = new_features, new_action\n",
    "                    revenue += reward\n",
    "            #print([m.name for m in possible_markets])\n",
    "            # Instead of updating the weights after each hour, the weights are updated after each market. This is to get a better estimate of the reward since the rewards are given after each of the markets are considererd for an hour.\n",
    "            if \"FCR_N_D_1_NO5\" in [m.name for m in possible_markets]: # The FCR D-1 markets has the latest deadline, so after these markets has been considered, all markets has been considered for the given hour.\n",
    "                # istead of updating the weights after each hour, the weights are updated after each market. This is to get a better estimate of the reward since the rewards are given after each of the markets are considererd for an hour.\n",
    "                # I should probably use a neural network to update the weights instead of using the Q-table. Must find out how to do it properly\n",
    "                #print(\"possible_hours : \", possible_hours)\n",
    "                print(\"amount of hours : \", len(possible_hours))\n",
    "                hourly_rewards = torch.tensor([reward_bid_hour_dict[bid_hour] for bid_hour in possible_hours], dtype=torch.float32) # should get 24 hours\n",
    "                #print(f\"hourly rewards : {hourly_rewards}\")\n",
    "                print(f\"hourly rewards shape : {hourly_rewards.shape}\")\n",
    "                actions = torch.tensor([action_feature_dict[(episode_n, market.name, hour)][0] for market in markets for hour in possible_hours], dtype=torch.long) # should get 24 hours * 6 markets\n",
    "                #print(f\"actions : {actions}\")\n",
    "                print(f\"actions shape : {actions.shape}\")\n",
    "                \n",
    "                new_actions = torch.tensor([action_feature_dict[(episode_n, market.name, hour)][1] for market in markets for hour in possible_hours], dtype=torch.long) # should get 24 hours * 6 markets\n",
    "                #print(f\"new_actions : {new_actions}\")\n",
    "                print(f\"new_actions shape : {new_actions.shape}\")\n",
    "                \n",
    "                #make tensors of the features and new_features for each hour for each market where each set of features are 11 features long\n",
    "                features = torch.stack([action_feature_dict[(episode_n, market.name, hour)][2] for market in markets for hour in possible_hours], dim = 0) # should get 24 hours * 6 markets * 11 features\n",
    "                #print(f\"features : {features}\")\n",
    "                print(f\"features shape : {features.shape}\")\n",
    "                new_features = torch.stack([action_feature_dict[(episode_n, market.name, hour)][3] for market in markets for hour in possible_hours], dim = 0)\n",
    "                #print(f\"new_features : {new_features}\")\n",
    "                print(f\"new_features shape : {new_features.shape}\")\n",
    "             \n",
    "                batch_size = len(actions)\n",
    "                weights, loss = update_weights(network, optimizer, actions,\\\n",
    "                                                new_actions, features, new_features, gamma, batch_size, hourly_rewards)\n",
    "                print(f\"weights after update: {weights}\")\n",
    "                ep_loss += loss\n",
    "\n",
    "\n",
    "        \n",
    "        episode_weights[episode_n] = weights.copy()        \n",
    "        bids[episode_n] = episode_bid_df.sort_values(by = [\"Hour\"])\n",
    "        revenues[episode_n] = revenue\n",
    "        asset_bids.append(episode_bid_dict)\n",
    "        episode_losses[episode_n] = ep_loss\n",
    "    return bids, revenues, available_assets, episode_weights, action_feature_dict, asset_bids, episode_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FCR_D_D_2_NO5', 'FCR_N_D_2_NO5']\n",
      "amount of hours :  24\n",
      "hourly rewards shape : torch.Size([24, 6])\n",
      "actions shape : torch.Size([144])\n",
      "new_actions shape : torch.Size([144])\n",
      "features shape : torch.Size([144, 11])\n",
      "new_features shape : torch.Size([144, 11])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (144) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bids, revenues, available_assets, weights, action_list, asset_bids, ep_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nstep_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_exp_price_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_exp_price_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_exp_vol_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_exp_vol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweather_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_da_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm_da_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 179\u001b[0m, in \u001b[0;36mtrain_nstep_model\u001b[0;34m(epsilon, alpha, gamma, num_episodes, L, M, H, norm_exp_price_dict, norm_exp_vol_dict, weather_dict, norm_da_df, n_actions, n_features)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_features shape : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_features\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(actions)\n\u001b[0;32m--> 179\u001b[0m weights, loss \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnew_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhourly_rewards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights after update: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m ep_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[47], line 24\u001b[0m, in \u001b[0;36mupdate_weights\u001b[0;34m(network, optimizer, actions, new_actions, features, new_features, gamma, batch_size, rewards)\u001b[0m\n\u001b[1;32m     21\u001b[0m next_q_values \u001b[38;5;241m=\u001b[39m network(new_features)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate the target Q-values including the immediate reward\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m target_q_values \u001b[38;5;241m=\u001b[39m \u001b[43mrewards\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnext_q_values\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(current_q_values, target_q_values\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (144) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "bids, revenues, available_assets, weights, action_list, asset_bids, ep_losses = train_nstep_model(epsilon = 0.3, alpha = 0.3, gamma = 0.9, num_episodes = 2, L = L, M = M, H = H, norm_exp_price_dict = norm_exp_price_dict, norm_exp_vol_dict = norm_exp_vol_dict, weather_dict= weather_dict, norm_da_df = norm_da_df, n_features= 11, n_actions= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, x, y, w, d = utils.run_optimization_model(L = L, M = M, F = F, H = H, Fu_h_l = Fu_h_l, Fd_h_l = Fd_h_l, R_h_l = R_h_l, Vp_h_m = Vp_h_m, Vm_m = Vm_m, R_m = R_m, Ir_hlm = Ir_hlm, Ia_hlm = Ia_hlm, Va_hm = Va_hm, compatible_list= compatible_list, log_filename= \"week_mod_no5.log\", model_name= \"week_mod_no5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-kode-mqTzi66U-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
